{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is a Jupyter notebook (work in progress) to visualize the data gathered during our testing with the SATURN patch.\n",
    "\n",
    "The basic data filtering approach will be as follows:\n",
    "\n",
    "For each dataset containing a time series of voltage readings:\n",
    "1. Trim the dataset's beginning and end for \"dead zones\" where there is no data.\n",
    "2. Smooth the dataset by taking the moving average.\n",
    "3. Split the dataset into individual segments, since one dataset typically contains 5 individual readings of 1 gesture.\n",
    "    \n",
    "Then the data can be visualized. We're trying a few different approaches:\n",
    "* [All Data](#All-Data) contains a list of the raw waveforms for all datasets. Useful for debugging.\n",
    "* [All Data, Sliced and Overlaid](#All-Data--Sliced-and-Overlaid) contains a chart for each waveform containing all the segments, adjusted to be the same length and overlaid upon each other. Useful for validating that input data is consistent.\n",
    "* [Segments by Gesture](#Segments-by-Gesture) contains a chart for each gesture. In each gesture chart, the segmented data from each configuration of SATURN (ex. with backing material, without backing material, large pad, small pad, etc.) is overlaid. This will help us determine what SATURN configurations produce the most differentiable signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "from numpy.fft import fft, fftfreq, ifft\n",
    "\n",
    "# Returns a list of the datasets in the data directory.\n",
    "# Each dataset in this list is a dict with three attributes:\n",
    "#   Dir: directory under data/ occupied by this dataset\n",
    "#   File: filename without extension\n",
    "#   Path: relative path to .csv\n",
    "def get_available_datasets():\n",
    "    data = []\n",
    "\n",
    "    for datafile in filter(lambda x: x[-4:] == '.csv',\n",
    "        list(itertools.chain(*[[root+'/'+file for file in files]\n",
    "        for root, _, files in os.walk('./data')]))):\n",
    "        \n",
    "        n = datafile.split('/')\n",
    "        data.append({\n",
    "            'Dir': n[-2],\n",
    "            'File': n[-1].split('.')[0],\n",
    "            'Path': datafile\n",
    "        })\n",
    "\n",
    "    return data\n",
    "\n",
    "# Returns a dataset's contents as a list.\n",
    "# If `raw` is not set, the results will be filtered and normalized.\n",
    "def load_dataset(datum, raw=False):\n",
    "    dataset = pd.read_csv(datum['Path'], names=['V'], header=None)\n",
    "    dataset = list(dataset['V'])\n",
    "    if not raw:  # normalize and filter the data\n",
    "        dataset = normalize_dataset(dataset)\n",
    "        dataset = trim_dataset(dataset)\n",
    "        dataset = moving_average(dataset, 20)\n",
    "        #dataset = segment_dataset(dataset, threshold=0.01, min_spacing=100)\n",
    "    return dataset\n",
    "\n",
    "# Normalize a dataset by dividing by max amplitude.\n",
    "def normalize_dataset(data):\n",
    "    return np.divide(data, np.max(data))\n",
    "\n",
    "# Removes all leading and trailing points that fall under a certain threshold.\n",
    "# The idea is to remove the irrelevant start and end portions of our data.\n",
    "# Returns the relevant slice.\n",
    "def trim_dataset(data, threshold=0.01):\n",
    "    i = 0\n",
    "    while abs(data[i]) < threshold and i < len(data):\n",
    "        i += 1\n",
    "    j = len(data) - 1\n",
    "    while abs(data[j]) < threshold and j > i:\n",
    "        j -= 1\n",
    "    return data[i:j]\n",
    "\n",
    "# Returns a list of the contiguous segments of the dataset.\n",
    "# A contiguous segment is defined as some slice separated by at least \n",
    "# `min_spacing` points where the signal is less than `threshold` from \n",
    "# the next segment.\n",
    "# Returns a list of lists (segments)\n",
    "def segment_dataset(data, threshold=0.01, min_spacing=100):\n",
    "    i = 0\n",
    "    spaces = 0\n",
    "    intervals = []\n",
    "    start = None\n",
    "    while i < len(data):\n",
    "        while abs(data[i]) < threshold and i < len(data): \n",
    "            i += 1\n",
    "        start = i\n",
    "        spaces = 0\n",
    "        end = i\n",
    "        while i < len(data):\n",
    "            if abs(data[i]) < threshold:\n",
    "                spaces += 1\n",
    "            else:\n",
    "                spaces = 0\n",
    "                end = i\n",
    "            if spaces > min_spacing:\n",
    "                intervals.append((start, end))\n",
    "                start = None\n",
    "                end = None\n",
    "    if start and not end:\n",
    "        intervals.append((start, i))\n",
    "    print(intervals)\n",
    "    return [data[interval[0]:interval[1]] for interval in intervals]\n",
    "\n",
    "# Given a `data` as a list and a `window_size` number, it will return\n",
    "# `data` with each point averaged with the previous `window_size` points.\n",
    "def moving_average(data, window_size):\n",
    "    res = []\n",
    "    for (i,t) in enumerate(data):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        start = i - window_size\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        end = i\n",
    "        sl = data[start:end]\n",
    "        x = np.average(sl)\n",
    "        res.append(x)\n",
    "    return res\n",
    "\n",
    "data = get_available_datasets()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)  # change size of charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (i, datum) in enumerate(data):\n",
    "    df = load_dataset(datum)\n",
    "    plt.figure(i)\n",
    "    plt.ylabel('Signal (V)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    w = plt.plot([float(i)*(float(1)/50) for i in range(0, len(df))], df, linewidth=1.0)\n",
    "    plt.title(datum['File'] + ' (' + datum['Dir'] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveforms by Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = {}\n",
    "for (i, datum) in enumerate(data):\n",
    "    if datum['File'] not in g:\n",
    "        g[datum['File']] = []\n",
    "    g[datum['File']].append(datum)\n",
    "for (i, gesture) in enumerate(g.keys()):\n",
    "    gdata = g[gesture]\n",
    "    plt.figure(i)\n",
    "    plt.ylabel('Signal (V)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    for datum in gdata:\n",
    "        df = load_dataset(datum)\n",
    "        w = plt.plot([float(i)*(float(1)/50) for i in range(0, len(df))], df, linewidth=1.0, label=datum['Dir'])\n",
    "    plt.title('All ' + gesture + ' Gestures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFT for each Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# time period (in s)\n",
    "time_range = 10\n",
    "\n",
    "datasets_dict = uty.get_available_datasets()\n",
    "for (i, datum) in enumerate(datasets_dict):\n",
    "    cur_dataset = uty.load_dataset(datum, raw=False)\n",
    "\n",
    "    freqs = fftfreq(len(cur_dataset))\n",
    "\n",
    "    # only include positive frequencies\n",
    "    mask = freqs > 0\n",
    "    fft_vals = fft(y)\n",
    "    \n",
    "    # range of x-values (time), one coordinate per data\n",
    "    x = np.linspace(0, time_range, len(cur_dataset))\n",
    "\n",
    "    # true theoretical fft\n",
    "    fft_theo = 2.0* np.abs(fft_vals/n)\n",
    "\n",
    "    plt.figure(i)\n",
    "    \n",
    "    plt.plot(freqs[mask], fft_theo[mask], label = 'true fft values')\n",
    "    plt.title('FFT values' +  datum['Dir'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
