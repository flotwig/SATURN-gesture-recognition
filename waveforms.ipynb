{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is a Jupyter notebook (work in progress) to visualize the data gathered during our testing with the SATURN patch.\n",
    "\n",
    "The basic data filtering approach will be as follows:\n",
    "\n",
    "For each dataset containing a time series of voltage readings:\n",
    "1. Trim the dataset's beginning and end for \"dead zones\" where there is no data.\n",
    "2. Smooth the dataset by taking the moving average.\n",
    "3. Split the dataset into individual segments, since one dataset typically contains 5 individual readings of 1 gesture.\n",
    "    \n",
    "Then the data can be visualized. We're trying a few different approaches:\n",
    "* [All Data](#All-Data) contains a list of the raw waveforms for all datasets. Useful for debugging.\n",
    "* [All Data, Sliced and Overlaid](#All-Data--Sliced-and-Overlaid) contains a chart for each waveform containing all the segments, adjusted to be the same length and overlaid upon each other. Useful for validating that input data is consistent.\n",
    "* [Segments by Gesture](#Segments-by-Gesture) contains a chart for each gesture. In each gesture chart, the segmented data from each configuration of SATURN (ex. with backing material, without backing material, large pad, small pad, etc.) is overlaid. This will help us determine what SATURN configurations produce the most differentiable signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "from numpy.fft import fft, fftfreq, ifft\n",
    "\n",
    "# Returns a list of the datasets in the data directory.\n",
    "# Each dataset in this list is a dict with three attributes:\n",
    "#   Dir: directory under data/ occupied by this dataset\n",
    "#   File: filename without extension\n",
    "#   Path: relative path to .csv\n",
    "def get_available_datasets():\n",
    "    data = []\n",
    "\n",
    "    for datafile in filter(lambda x: x[-4:] == '.csv',\n",
    "        list(itertools.chain(*[[root+'/'+file for file in files]\n",
    "        for root, _, files in os.walk('./data')]))):\n",
    "        \n",
    "        n = datafile.split('/')\n",
    "        data.append({\n",
    "            'Dir': n[-2],\n",
    "            'File': n[-1].split('.')[0],\n",
    "            'Path': datafile\n",
    "        })\n",
    "\n",
    "    return data\n",
    "\n",
    "# Returns a dataset's contents as a list.\n",
    "# If `raw` is not set, the results will be filtered and normalized.\n",
    "def load_dataset(datum, raw=False):\n",
    "    dataset = pd.read_csv(datum['Path'], names=['V'], header=None)\n",
    "    dataset = list(dataset['V'])\n",
    "    if not raw:  # normalize and filter the data\n",
    "        dataset = normalize_dataset(dataset)\n",
    "        dataset = trim_dataset(dataset)\n",
    "        dataset = moving_average(dataset, 20)\n",
    "        #dataset = segment_dataset(dataset, threshold=0.01, min_spacing=100)\n",
    "    return dataset\n",
    "\n",
    "# Normalize a dataset by dividing by max amplitude.\n",
    "def normalize_dataset(data):\n",
    "    return np.divide(data, np.max(data))\n",
    "\n",
    "# Removes all leading and trailing points that fall under a certain threshold.\n",
    "# The idea is to remove the irrelevant start and end portions of our data.\n",
    "# Returns the relevant slice.\n",
    "def trim_dataset(data, threshold=0.01):\n",
    "    i = 0\n",
    "    while abs(data[i]) < threshold and i < len(data):\n",
    "        i += 1\n",
    "    j = len(data) - 1\n",
    "    while abs(data[j]) < threshold and j > i:\n",
    "        j -= 1\n",
    "    return data[i:j]\n",
    "\n",
    "# Returns a list of the contiguous segments of the dataset.\n",
    "# A contiguous segment is defined as some slice separated by at least \n",
    "# `min_spacing` points where the signal is less than `threshold` from \n",
    "# the next segment.\n",
    "# Returns a list of lists (segments)\n",
    "def segment_dataset(data, threshold=0.01, min_spacing=100):\n",
    "    i = 0\n",
    "    spaces = 0\n",
    "    intervals = []\n",
    "    start = None\n",
    "    while i < len(data):\n",
    "        while abs(data[i]) < threshold and i < len(data): \n",
    "            i += 1\n",
    "        start = i\n",
    "        spaces = 0\n",
    "        end = i\n",
    "        while i < len(data):\n",
    "            if abs(data[i]) < threshold:\n",
    "                spaces += 1\n",
    "            else:\n",
    "                spaces = 0\n",
    "                end = i\n",
    "            if spaces > min_spacing:\n",
    "                intervals.append((start, end))\n",
    "                start = None\n",
    "                end = None\n",
    "    if start and not end:\n",
    "        intervals.append((start, i))\n",
    "    print(intervals)\n",
    "    return [data[interval[0]:interval[1]] for interval in intervals]\n",
    "\n",
    "# Given a `data` as a list and a `window_size` number, it will return\n",
    "# `data` with each point averaged with the previous `window_size` points.\n",
    "def moving_average(data, window_size):\n",
    "    res = []\n",
    "    for (i,t) in enumerate(data):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        start = i - window_size\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        end = i\n",
    "        sl = data[start:end]\n",
    "        x = np.average(sl)\n",
    "        res.append(x)\n",
    "    return res\n",
    "\n",
    "data = get_available_datasets()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)  # change size of charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (i, datum) in enumerate(data):\n",
    "    df = load_dataset(datum)\n",
    "    plt.figure(i)\n",
    "    plt.ylabel('Signal (V)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    w = plt.plot([float(i)*(float(1)/50) for i in range(0, len(df))], df, linewidth=1.0)\n",
    "    plt.title(datum['File'] + ' (' + datum['Dir'] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveforms by Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = {}\n",
    "for (i, datum) in enumerate(data):\n",
    "    if datum['File'] not in g:\n",
    "        g[datum['File']] = []\n",
    "    g[datum['File']].append(datum)\n",
    "for (i, gesture) in enumerate(g.keys()):\n",
    "    gdata = g[gesture]\n",
    "    plt.figure(i)\n",
    "    plt.ylabel('Signal (V)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    for datum in gdata:\n",
    "        df = load_dataset(datum)\n",
    "        w = plt.plot([float(i)*(float(1)/50) for i in range(0, len(df))], df, linewidth=1.0, label=datum['Dir'])\n",
    "    plt.title('All ' + gesture + ' Gestures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFT for each Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets_dict = get_available_datasets()\n",
    "# for (i, datum) in enumerate(datasets_dict):\n",
    "#     cur_dataset = load_dataset(datum, raw=False)\n",
    "#     time_range = len(cur_dataset)/50000\n",
    "\n",
    "#     freqs = fftfreq(len(cur_dataset))\n",
    "\n",
    "#     # only include positive frequencies\n",
    "#     mask = freqs > 0\n",
    "#     fft_vals = fft(cur_dataset)\n",
    "    \n",
    "#     # range of x-values (time), one coordinate per data\n",
    "#     x = np.linspace(0, time_range, len(cur_dataset))\n",
    "\n",
    "#     # true theoretical fft\n",
    "#     fft_theo = 2.0* np.abs(fft_vals/len(cur_dataset))\n",
    "\n",
    "#     plt.figure(i)\n",
    "    \n",
    "#     plt.plot(freqs[mask], fft_theo[mask], label = 'true fft values')\n",
    "#     plt.title('FFT values' +  datum['Dir'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation (finding Gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findGesturesOfAllData():\n",
    "    datasets_dict = get_available_datasets()\n",
    "    map_dataname_to_gestures_indices_list = {}\n",
    "    \n",
    "    for (i, datum) in enumerate(datasets_dict):\n",
    "        cur_dataset = load_dataset(datum, raw=False)\n",
    "        total_time_range = len(cur_dataset)/50000\n",
    "\n",
    "        sample_win_size = 50000\n",
    "        start_win = 0\n",
    "        end_win = 49999\n",
    "        \n",
    "        map_start_to_fft_sum = {}\n",
    "        signals_list = []\n",
    "        \n",
    "        # list of sums of all fft bin for each window used on this dataset \n",
    "        # each window represents one second of the signal\n",
    "        list_of_fftSums = []\n",
    "\n",
    "        \n",
    "        while end_win < len(cur_dataset):\n",
    "            \n",
    "            # each window covers an event occuring in one second of time\n",
    "            window_data = cur_dataset[start_win:end_win]\n",
    "            \n",
    "            freqs = fftfreq(len(window_data))\n",
    "            ##sum_of_fftBins = sum(np.abs(freqs))\n",
    "\n",
    "            # getting sum of fft bins, then the sum of their frequency values\n",
    "            \n",
    "            fft_vals = fft(window_data)\n",
    "            # fftTheo = 2.0* np.abs(fft_vals/len(cur_dataset))\n",
    "            ## sum_of_values = sum(fft_theo)\n",
    "\n",
    "            sum_of_fftValues = sum(np.abs(fft_vals) / 50000)\n",
    "\n",
    "            # appending sum of the fftbins to list \n",
    "            list_of_fftSums += [sum_of_fftValues]\n",
    "            \n",
    "            # update the window size to include 50000 samples, half new and half old.\n",
    "            start_win += 25000\n",
    "            end_win += 25000\n",
    "            print(sum_of_fftValues)\n",
    "        \n",
    "        list_of_gesture_starts = []\n",
    "        # variables to toggle as any local maxima or minima are found in list_of_fftSums.\n",
    "        gesture_start_found = False\n",
    "        gesture_end_found = False\n",
    "        for i in range(len(list_of_fftSums)):\n",
    "            \n",
    "            # We will compare against prev. and next sums to determine if a new\n",
    "            # gesture is starting or ending\n",
    "            if i + 1 < len(list_of_fftSums):\n",
    "                if len(list_of_gesture_starts) == 0:\n",
    "                    if list_of_fftSums[i+1] <= list_of_fftSums[i] and list_of_fftSums[i-1] < list_of_fftSums[i]:\n",
    "\n",
    "                        gesture_end_found = False\n",
    "                        gesture_start_found = True\n",
    "                        \n",
    "                        # we assume gesture ends in this window so data in l._o._g._s. has a consistent type always\n",
    "                        list_of_gesture_starts += [(i*25000, i*25000 + 50000)]\n",
    "                        \n",
    "                elif (gesture_start_found and list_of_fftSums[i+1] >= list_of_fftSums[i] and\n",
    "                      list_of_fftSums[i-1] > list_of_fftSums[i]):\n",
    "                    \n",
    "                    # if end of gesture is found (a local minimum in list of sums) record it in end of tuple\n",
    "                    # of last element in l._o._g._s.\n",
    "                    gesture_end_found = True\n",
    "                    gesture_start_found = False\n",
    "                    temp = list_of_gesture_starts[-1]\n",
    "                    list_of_gesture_starts[-1] = (temp, (i - 1)*25000 + 25000)\n",
    "                    temp = None\n",
    "                    \n",
    "                elif (gesture_end_found and list_of_fftSums[i+1] <= list_of_fftSums[i] and\n",
    "                    list_of_fftSums[i-1] < list_of_fftSums[i]):\n",
    "                        \n",
    "                    gesture_end_found = False\n",
    "                    gesture_start_found = True\n",
    "                    \n",
    "                    # we assume gesture ends in this window so data in l._o._g._s. has a consistent type always\n",
    "                    list_of_gesture_starts += [(i*25000, i*25000 + 50000)]\n",
    "        \n",
    "        print(list_of_gesture_starts)\n",
    "        map_dataname_to_gestures_indices_list[datum['Path']] = list_of_gesture_starts\n",
    "        \n",
    "        print('____')\n",
    "        #go to next dataset\n",
    "\n",
    "# returns the list of gesture events happening in dataset\n",
    "# data: a data file object, can be opened with call to load_dataset()\n",
    "def findGesturesInGivenData(data):\n",
    "    cur_dataset = load_dataset(data, raw=False)\n",
    "    time_range = len(cur_dataset)/50000\n",
    "\n",
    "    win_size = 50000\n",
    "    start_win = 0\n",
    "    end_win = 49999\n",
    "        \n",
    "    map_start_to_fft_sum = {}\n",
    "    signals_list = []\n",
    "        \n",
    "    # list of sums of all fft bin for each window used on this dataset \n",
    "    # each window represents one second of the signal\n",
    "    list_of_fftSums = []\n",
    "\n",
    "        \n",
    "    while end_win < len(cur_dataset):\n",
    "            \n",
    "        # each window covers an event occuring in one second of time\n",
    "        window_data = cur_dataset[start_win:end_win]\n",
    "        freqs = fftfreq(len(window_data))\n",
    "            \n",
    "        # fft_vals = fft(window_data)\n",
    "        \n",
    "        # getting sum of fft bins, then the sum of their frequency values\n",
    "        sum_of_fftBins = sum(np.abs(freqs))\n",
    "        ## sum_of_values = sum(fft_theo)\n",
    "            \n",
    "            \n",
    "        # appending sum of the fftbins to list \n",
    "        list_of_fftSums += [sum_of_fftBins]\n",
    "\n",
    "        # update the window size to include 50000 samples, half new and half old.\n",
    "        start_win += 25000\n",
    "        end_win += 25000\n",
    "\n",
    "\n",
    "    list_of_gesture_starts = []\n",
    "    # variables to toggle as any local maxima or minima are found in list_of_fftSums.\n",
    "    gesture_start_found = False\n",
    "    gesture_end_found = False\n",
    "    for i in range(len(list_of_fftSums)):\n",
    "\n",
    "        # We will compare against prev. and next sums to determine if a new\n",
    "        # gesture is starting or ending\n",
    "        if i + 1 < len(list_of_fftSums):\n",
    "            if len(list_of_gesture_starts) == 0:\n",
    "                if (list_of_fftSums[i+1] <= list_of_fftSums[i] and \n",
    "                    list_of_fftSums[i-1] < list_of_fftSums[i]):\n",
    "\n",
    "                    gesture_end_found = False\n",
    "                    gesture_start_found = True\n",
    "\n",
    "                    # we assume gesture ends in this window so data in l._o._g._s. has a consistent type always\n",
    "                    list_of_gesture_starts += [(i*25000, i*25000 + 50000)]\n",
    "\n",
    "            elif (gesture_start_found and list_of_fftSums[i+1] >= list_of_fftSums[i] and \n",
    "                list_of_fftSums[i-1] > list_of_fftSums[i]):\n",
    "\n",
    "                # if end of gesture is found (a local minimum in list of sums) record it in end of tuple\n",
    "                # of last element in l._o._g._s.\n",
    "                gesture_end_found = True\n",
    "                gesture_start_found = False\n",
    "                temp = list_of_gesture_starts[-1]\n",
    "                list_of_gesture_starts[-1] = (temp, (i - 1)*25000 + 25000)\n",
    "                temp = None\n",
    "\n",
    "            elif (gesture_end_found and list_of_fftSums[i+1] <= list_of_fftSums[i] and\n",
    "                list_of_fftSums[i-1] < list_of_fftSums[i]):\n",
    "\n",
    "                gesture_end_found = False\n",
    "                gesture_start_found = True\n",
    "\n",
    "                # we assume gesture ends in this window so data in l._o._g._s. has a consistent type always\n",
    "                list_of_gesture_starts += [(i*25000, i*25000 + 50000)]\n",
    "\n",
    "    return list_of_gesture_starts\n",
    "\n",
    "findGesturesOfAllData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
