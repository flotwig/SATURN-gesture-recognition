{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is a Jupyter notebook (work in progress) to visualize the data gathered during our testing with the SATURN patch.\n",
    "\n",
    "The basic data filtering approach will be as follows:\n",
    "\n",
    "For each dataset containing a time series of voltage readings:\n",
    "1. Trim the dataset's beginning and end for \"dead zones\" where there is no data.\n",
    "2. Smooth the dataset by taking the moving average.\n",
    "3. Split the dataset into individual segments, since one dataset typically contains 5 individual readings of 1 gesture.\n",
    "    \n",
    "Then the data can be visualized. We're trying a few different approaches:\n",
    "* [All Data](#All-Data) contains a list of the raw waveforms for all datasets. Useful for debugging.\n",
    "* [All Data, Sliced and Overlaid](#All-Data--Sliced-and-Overlaid) contains a chart for each waveform containing all the segments, adjusted to be the same length and overlaid upon each other. Useful for validating that input data is consistent.\n",
    "* [Segments by Gesture](#Segments-by-Gesture) contains a chart for each gesture. In each gesture chart, the segmented data from each configuration of SATURN (ex. with backing material, without backing material, large pad, small pad, etc.) is overlaid. This will help us determine what SATURN configurations produce the most differentiable signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 50000\n",
      "(array([    1,     0,     0,     0, 49999]), array([-49.51832339+0.j        , -38.98671889+0.05266512j,\n",
      "       -28.45511438+0.10533024j, -17.92350988+0.15799537j,\n",
      "        -7.39190538+0.21066049j,   3.13969913+0.26332561j]))\n",
      "25000.0 75000.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zach/.config/miniconda3/lib/python3.7/site-packages/numpy/lib/histograms.py:761: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  indices = f_indices.astype(np.intp)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "from numpy.fft import fft, fftfreq, ifft\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)  # change size of charts\n",
    "\n",
    "# Returns a list of the datasets in the data directory.\n",
    "# Each dataset in this list is a dict with three attributes:\n",
    "#   Dir: directory under data/ occupied by this dataset\n",
    "#   File: filename without extension\n",
    "#   Path: relative path to .csv\n",
    "def get_available_datasets():\n",
    "    data = []\n",
    "\n",
    "    for datafile in filter(lambda x: x[-4:] == '.csv',\n",
    "        list(itertools.chain(*[[root+'/'+file for file in files]\n",
    "        for root, _, files in os.walk('./data')]))):\n",
    "        \n",
    "        n = datafile.split('/')\n",
    "        data.append({\n",
    "            'Dir': n[-2],\n",
    "            'File': n[-1].split('.')[0],\n",
    "            'Path': datafile\n",
    "        })\n",
    "\n",
    "    return data\n",
    "\n",
    "# Returns a dataset's contents as a list.\n",
    "# If `raw` is not set, the results will be filtered and normalized.\n",
    "def load_dataset(datum):\n",
    "    dataset = pd.read_csv(datum['Path'], names=['V'], header=None)\n",
    "    dataset = list(dataset['V'])\n",
    "    return dataset\n",
    "\n",
    "# Generator that, given a dataset, yields gestures\n",
    "def sliding_window(signal, window_length=50000, overlap=.5, fft_bins=5):\n",
    "    N = len(signal)\n",
    "    start, end = 0, min(window_length, N)\n",
    "    while end <= N:\n",
    "        print(start, end)\n",
    "        window = signal[start:end]\n",
    "        freqs = fft(window)  # todo: do we need to use a norm= normalization?\n",
    "        freq_bins = np.histogram(freqs, bins=fft_bins)\n",
    "        print(freq_bins)\n",
    "        start = end - (window_length * overlap)\n",
    "        end = start + window_length\n",
    "        print(start, end)\n",
    "        break\n",
    "\n",
    "\n",
    "data = get_available_datasets()\n",
    "sliding_window(load_dataset(data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (i, datum) in enumerate(data):\n",
    "    df = load_dataset(datum)\n",
    "    plt.figure(i)\n",
    "    plt.ylabel('Signal (V)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    w = plt.plot([float(i)*(float(1)/50) for i in range(0, len(df))], df, linewidth=1.0)\n",
    "    plt.title(datum['File'] + ' (' + datum['Dir'] + ')')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
