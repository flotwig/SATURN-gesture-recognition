{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This is a Jupyter notebook (work in progress) to visualize the data gathered during our testing with the SATURN patch.\n",
    "\n",
    "The basic data filtering approach will be as follows:\n",
    "\n",
    "For each dataset containing a time series of voltage readings:\n",
    "1. Trim the dataset's beginning and end for \"dead zones\" where there is no data.\n",
    "2. Smooth the dataset by taking the moving average.\n",
    "3. Split the dataset into individual segments, since one dataset typically contains 5 individual readings of 1 gesture.\n",
    "    \n",
    "Then the data can be visualized. We're trying a few different approaches:\n",
    "* [All Data](#All-Data) contains a list of the raw waveforms for all datasets. Useful for debugging.\n",
    "* [All Data, Sliced and Overlaid](#All-Data--Sliced-and-Overlaid) contains a chart for each waveform containing all the segments, adjusted to be the same length and overlaid upon each other. Useful for validating that input data is consistent.\n",
    "* [Segments by Gesture](#Segments-by-Gesture) contains a chart for each gesture. In each gesture chart, the segmented data from each configuration of SATURN (ex. with backing material, without backing material, large pad, small pad, etc.) is overlaid. This will help us determine what SATURN configurations produce the most differentiable signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import os\n",
    "from numpy.fft import fft, fftfreq, ifft, rfft\n",
    "\n",
    "# Returns a list of the datasets in the data directory.\n",
    "# Each dataset in this list is a dict with three attributes:\n",
    "#   Dir: directory under data/ occupied by this dataset\n",
    "#   File: filename without extension\n",
    "#   Path: relative path to .csv\n",
    "def get_available_datasets():\n",
    "    data = []\n",
    "\n",
    "    for datafile in filter(lambda x: x[-4:] == '.csv',\n",
    "        list(itertools.chain(*[[root+'/'+file for file in files]\n",
    "        for root, _, files in os.walk('./data')]))):\n",
    "        \n",
    "        n = datafile.split('/')\n",
    "        data.append({\n",
    "            'Dir': n[-2],\n",
    "            'File': n[-1].split('.')[0],\n",
    "            'Path': datafile\n",
    "        })\n",
    "\n",
    "    return data\n",
    "\n",
    "# Returns a dataset's contents as a list.\n",
    "# If `raw` is not set, the results will be filtered and normalized.\n",
    "def load_dataset(datum, raw=False):\n",
    "    dataset = pd.read_csv(datum['Path'], names=['V'], header=None)\n",
    "    dataset = list(dataset['V'])\n",
    "    if not raw:  # normalize and filter the data\n",
    "        dataset = normalize_dataset(dataset)\n",
    "        dataset = trim_dataset(dataset)\n",
    "        dataset = moving_average(dataset, 20)\n",
    "        #dataset = segment_dataset(dataset, threshold=0.01, min_spacing=100)\n",
    "    return dataset\n",
    "\n",
    "# Normalize a dataset by dividing by max amplitude.\n",
    "def normalize_dataset(data):\n",
    "    return np.divide(data, np.max(data))\n",
    "\n",
    "# Removes all leading and trailing points that fall under a certain threshold.\n",
    "# The idea is to remove the irrelevant start and end portions of our data.\n",
    "# Returns the relevant slice.\n",
    "def trim_dataset(data, threshold=0.01):\n",
    "    i = 0\n",
    "    while abs(data[i]) < threshold and i < len(data):\n",
    "        i += 1\n",
    "    j = len(data) - 1\n",
    "    while abs(data[j]) < threshold and j > i:\n",
    "        j -= 1\n",
    "    return data[i:j]\n",
    "\n",
    "# Returns a list of the contiguous segments of the dataset.\n",
    "# A contiguous segment is defined as some slice separated by at least \n",
    "# `min_spacing` points where the signal is less than `threshold` from \n",
    "# the next segment.\n",
    "# Returns a list of lists (segments)\n",
    "def segment_dataset(data, threshold=0.01, min_spacing=100):\n",
    "    i = 0\n",
    "    spaces = 0\n",
    "    intervals = []\n",
    "    start = None\n",
    "    while i < len(data):\n",
    "        while abs(data[i]) < threshold and i < len(data): \n",
    "            i += 1\n",
    "        start = i\n",
    "        spaces = 0\n",
    "        end = i\n",
    "        while i < len(data):\n",
    "            if abs(data[i]) < threshold:\n",
    "                spaces += 1\n",
    "            else:\n",
    "                spaces = 0\n",
    "                end = i\n",
    "            if spaces > min_spacing:\n",
    "                intervals.append((start, end))\n",
    "                start = None\n",
    "                end = None\n",
    "    if start and not end:\n",
    "        intervals.append((start, i))\n",
    "    print(intervals)\n",
    "    return [data[interval[0]:interval[1]] for interval in intervals]\n",
    "\n",
    "# Given a `data` as a list and a `window_size` number, it will return\n",
    "# `data` with each point averaged with the previous `window_size` points.\n",
    "def moving_average(data, window_size):\n",
    "    res = []\n",
    "    for (i,t) in enumerate(data):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        start = i - window_size\n",
    "        if start < 0:\n",
    "            start = 0\n",
    "        end = i\n",
    "        sl = data[start:end]\n",
    "        x = np.average(sl)\n",
    "        res.append(x)\n",
    "    return res\n",
    "\n",
    "data = get_available_datasets()\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)  # change size of charts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for (i, datum) in enumerate(data):\n",
    "    df = load_dataset(datum)\n",
    "    plt.figure(i)\n",
    "    plt.ylabel('Signal (V)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    w = plt.plot([float(i)*(float(1)/50) for i in range(0, len(df))], df, linewidth=1.0)\n",
    "    plt.title(datum['File'] + ' (' + datum['Dir'] + ')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveforms by Gesture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = {}\n",
    "for (i, datum) in enumerate(data):\n",
    "    if datum['File'] not in g:\n",
    "        g[datum['File']] = []\n",
    "    g[datum['File']].append(datum)\n",
    "for (i, gesture) in enumerate(g.keys()):\n",
    "    gdata = g[gesture]\n",
    "    plt.figure(i)\n",
    "    plt.ylabel('Signal (V)')\n",
    "    plt.xlabel('Time (ms)')\n",
    "    for datum in gdata:\n",
    "        df = load_dataset(datum)\n",
    "        w = plt.plot([float(i)*(float(1)/50) for i in range(0, len(df))], df, linewidth=1.0, label=datum['Dir'])\n",
    "    plt.title('All ' + gesture + ' Gestures')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FFT for each Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets_dict = get_available_datasets()\n",
    "# for (i, datum) in enumerate(datasets_dict):\n",
    "#     cur_dataset = load_dataset(datum, raw=False)\n",
    "#     time_range = len(cur_dataset)/50000\n",
    "\n",
    "#     freqs = fftfreq(len(cur_dataset))\n",
    "\n",
    "#     # only include positive frequencies\n",
    "#     mask = freqs > 0\n",
    "#     fft_vals = fft(cur_dataset)\n",
    "    \n",
    "#     # range of x-values (time), one coordinate per data\n",
    "#     x = np.linspace(0, time_range, len(cur_dataset))\n",
    "\n",
    "#     # true theoretical fft\n",
    "#     fft_theo = 2.0* np.abs(fft_vals/len(cur_dataset))\n",
    "\n",
    "#     plt.figure(i)\n",
    "    \n",
    "#     plt.plot(freqs[mask], fft_theo[mask], label = 'true fft values')\n",
    "#     plt.title('FFT values' +  datum['Dir'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation (finding Gestures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____ ./data/small-pad-crazy/swipedown.csv\n",
      "Best threshold for ./data/small-pad-crazy/swipedown.csv: 10.256410256410255 and win_size=180 with 16 gestures\n",
      "____ ./data/small-pad-crazy/swipeup.csv\n",
      "Best threshold for ./data/small-pad-crazy/swipeup.csv: 38.97435897435897 and win_size=186 with 16 gestures\n",
      "____ ./data/small-pad-crazy/swiperight.csv\n",
      "Best threshold for ./data/small-pad-crazy/swiperight.csv: 32.82051282051282 and win_size=180 with 16 gestures\n",
      "____ ./data/small-pad-crazy/swipeleft.csv\n",
      "Best threshold for ./data/small-pad-crazy/swipeleft.csv: 36.92307692307692 and win_size=180 with 16 gestures\n"
     ]
    }
   ],
   "source": [
    "def find_gestures_in_all_datasets(path_filter=\"\"):\n",
    "    datasets_dict = get_available_datasets()\n",
    "    map_dataname_to_gestures_indices_list = {}\n",
    "    \n",
    "    for (i, datum) in enumerate(datasets_dict):\n",
    "        if path_filter not in datum['Path']:\n",
    "            continue\n",
    "        print('____', datum['Path'])\n",
    "        dataset = load_dataset(datum, raw=False)\n",
    "        gestures = find_gestures_in_dataset(dataset)\n",
    "        yield gestures\n",
    "        \n",
    "      \n",
    "# little test function to empiracally determine the best sample_win_size and threshold for dataset\n",
    "def find_gestures_in_new_small_pad_datasets(path_filter=\"small-pad-\"):\n",
    "    #500Hz\n",
    "    datasets_dict = get_available_datasets()\n",
    "    map_dataname_to_gestures_indices_list = {}\n",
    "    \n",
    "    for (i, datum) in enumerate(datasets_dict):\n",
    "        if path_filter not in datum['Path']:\n",
    "            continue\n",
    "        print('____', datum['Path'])\n",
    "        dataset = load_dataset(datum, raw=False)\n",
    "        best_gestures = []\n",
    "        best_threshold = 0\n",
    "        target_gestures = 16\n",
    "        best_win_size = 0\n",
    "        for sample_win_size in np.linspace(180, 200, num=10):\n",
    "            sample_win_size = int(sample_win_size)\n",
    "            for threshold in np.linspace(0, 80, num=40):\n",
    "                gestures = find_gestures_in_dataset(dataset, sample_win_size=sample_win_size, threshold=threshold)\n",
    "                if abs(len(gestures) - target_gestures) < abs(len(best_gestures) - target_gestures) or len(best_gestures) == 0:\n",
    "                    best_gestures = gestures\n",
    "                    best_threshold = threshold\n",
    "                    best_win_size = sample_win_size\n",
    "        print(\"Best threshold for \" + datum['Path'] + \": \" + str(best_threshold) + \" and win_size=\" + str(best_win_size) + \" with \" + str(len(best_gestures)) + \" gestures\")\n",
    "        map_dataname_to_gestures_indices_list[datum['Path']] = best_gestures\n",
    "        \n",
    "        #go to next dataset\n",
    "\n",
    "# returns the list of gesture events happening in dataset\n",
    "# cur_dataset: a list of readings\n",
    "def find_gestures_in_dataset(cur_dataset, sample_win_size=50000, overlap=.5, threshold=45000):\n",
    "    total_time_range = len(cur_dataset)/sample_win_size\n",
    "\n",
    "    start_win = 0\n",
    "    end_win = sample_win_size\n",
    "    slide_amount = round(sample_win_size * overlap)\n",
    "\n",
    "    map_start_to_fft_sum = {}\n",
    "    signals_list = []\n",
    "\n",
    "    # list of sums of all fft bin for each window used on this dataset \n",
    "    # each window represents one second of the signal\n",
    "    list_of_fftSums = []\n",
    "\n",
    "    \n",
    "    while start_win < len(cur_dataset):\n",
    "\n",
    "        # each window covers an event occuring in one second of time\n",
    "        window_data = cur_dataset[start_win:end_win]\n",
    "\n",
    "        freqs = fftfreq(len(window_data))\n",
    "        ##sum_of_fftBins = sum(np.abs(freqs))\n",
    "\n",
    "        # getting sum of fft bins, then the sum of their frequency values\n",
    "\n",
    "        fft_vals = rfft(window_data)\n",
    "        # fftTheo = 2.0* np.abs(fft_vals/len(cur_dataset))\n",
    "        ## sum_of_values = sum(fft_theo)\n",
    "\n",
    "        sum_of_fftValues = sum(np.abs(fft_vals))\n",
    "\n",
    "        # scale smaller slices - no idea if this is accurate\n",
    "        sum_of_fftValues *= np.round(sample_win_size / (end_win - start_win))\n",
    "\n",
    "        # appending sum of the fftbins to list \n",
    "        list_of_fftSums += [sum_of_fftValues]\n",
    "\n",
    "        # update the window size to include 50000 samples, half new and half old.\n",
    "        start_win += slide_amount\n",
    "        end_win = min(end_win + slide_amount, len(cur_dataset))\n",
    "\n",
    "        #print(sum_of_fftValues)\n",
    "\n",
    "    #print(\"Threshold: \" + str(threshold))\n",
    "    fftSums = list_of_fftSums\n",
    "    i = 0\n",
    "    gestures = []\n",
    "    while i < len(fftSums):\n",
    "        if fftSums[i] > threshold:\n",
    "            start = i\n",
    "            while i < len(fftSums) and fftSums[i] > threshold:\n",
    "                i += 1\n",
    "            end = i\n",
    "            gestures += [int(slide_amount*start), int(slide_amount*end)]\n",
    "        i += 1\n",
    "\n",
    "    #print(gestures)\n",
    "    return gestures\n",
    "\n",
    "# determines the best thresholds\n",
    "find_gestures_in_new_small_pad_datasets()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification (which gesture?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_gestures_in_all_datasets(path_filter=\"small-pad-crazy\"):"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
